# Paper

* **Title**: Pixel Recurrent Neural Networks
* **Authors**: Aaron van den Oord, Nal Kalchbrenner, Koray Kavukcuoglu
* **Link**: http://arxiv.org/abs/1601.06759
* **Tags**: Neural Network, recurrent, generative model, LSTM
* **Year**: 2016

# Summary

* What
  * The authors describe multiple architectures that can model the distributions of images.
  * These networks can be used to generate new images or to complete existing ones.
  * The networks are mostly based on RNNs.

* How
  * They define three architectures:
    * Row LSTM: TODO
    * Diagonal BiLSTM: TODO
    * PixelCNN: TODO

* Results
  * The softmax layers learn reasonable distributions. E.g. neighboring colors end up with similar probabilities. Values 0 and 255 tend to have higher probabilities than others, especially for the very first pixel.
  * In the 12-layer LSTM row model, residual and skip connections seem to have roughly the same effect on the network's results. Using both yields a tiny improvement over just using one of the techniques alone.
  * They achieve a slightly better result on MNIST than DRAW did.
  * Their negative log likelihood results for CIFAR-10 improve upon previous models. The diagonal BiLSTM model performs best, followed by the row LSTM model, followed by PixelCNN.
  * Their generated images for CIFAR-10 and Imagenet capture real local spatial dependencies. The multi-scale model produces better looking results. The images do not appear blurry. Overall they still look very unreal.

![Module A](images/Inception_v4__module_a.png?raw=true "Module A")
